{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports necesarios\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST con K-vecinos más vercanos\n",
    "En esta segunda sesión práctica vamos a entrenar clasificadores basados en distancias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joan/anaconda3/lib/python3.10/site-packages/sklearn/datasets/_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_openml(\"mnist_784\")\n",
    "\n",
    "print(mnist.data.shape)\n",
    "print(mnist.target.shape)\n",
    "\n",
    "data = mnist.data\n",
    "targets = mnist.target \n",
    "\n",
    "targets=targets.to_numpy()\n",
    "targets=np.int8(targets)\n",
    "\n",
    "data=data.to_numpy()\n",
    "data=np.float32(data)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partición de los datos\n",
    "\n",
    "Vamos a partir los datos en tres conjuntos: training, validation y test. Con un 80%, 10% y 10% respectivamente. \n",
    "\n",
    "Emplearemos el conjunto de training para aprender los parámetros del modelos, el conjunto de validation para escoger los mejores hiperparámetros. Finalmente reportaremos el resultado final sobre el conjunto de test."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio 1**    \n",
    "\n",
    "Realiza la partición de los datos en las particiones definidas (80%,10%,10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partición de los datos\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, targets, test_size = 0.2, random_state= 23)\n",
    "\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size = 0.5, random_state=23)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio 2**   \n",
    "\n",
    "Prueba un clasificador KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kne = KNeighborsClassifier()\n",
    "\n",
    "kne.fit(x_train, y_train)\n",
    "y_pred = kne.predict(x_val)\n",
    "acc = accuracy_score(y_pred, y_val)\n",
    "print(\"la precision es :\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la precision es : 0.9734285714285714\n"
     ]
    }
   ],
   "source": [
    "## Prueba el clasificador KNeighborsClassifier\n",
    "\n",
    "kne = KNeighborsClassifier()\n",
    "\n",
    "kne.fit(x_train, y_train)\n",
    "y_pred = kne.predict(x_test)\n",
    "acc = accuracy_score(y_pred, y_test)\n",
    "print(\"la precision es :\", acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio 3**   \n",
    "\n",
    "Encuentra el mejor valor de \"K\" con el conjunto de validación y obtén el resultados para test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la precision para 1 vecinos es : 0.9721428571428572\n",
      "la precision para 2 vecinos es : 0.9672857142857143\n",
      "la precision para 3 vecinos es : 0.9724285714285714\n",
      "la precision para 4 vecinos es : 0.9711428571428572\n",
      "la precision para 5 vecinos es : 0.9714285714285714\n",
      "la precision para 6 vecinos es : 0.9724285714285714\n",
      "la precision para 7 vecinos es : 0.9697142857142858\n",
      "la precision para 8 vecinos es : 0.9681428571428572\n",
      "la precision para 9 vecinos es : 0.9675714285714285\n",
      "la precision para 10 vecinos es : 0.968\n",
      "la precision para 20 vecinos es : 0.9605714285714285\n"
     ]
    }
   ],
   "source": [
    "## Estimar el mejor parámetro K con el conjunto de validación\n",
    "\n",
    "for i in [1,2,3,4,5,6,7,8,9,10,20]:    \n",
    "    kne = KNeighborsClassifier(n_neighbors=i)\n",
    "\n",
    "    kne.fit(x_train, y_train)\n",
    "    y_pred = kne.predict(x_val)\n",
    "    acc = accuracy_score(y_pred, y_val)\n",
    "    print(\"la precision para\", i,\"vecinos es :\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la precision para 6 vecinos es : 0.9731428571428572\n"
     ]
    }
   ],
   "source": [
    "## Obtener tasa de acierto con el conjunto de test para el mejor K\n",
    "x_train_comp =np.concatenate((x_train, x_val), axis =0)\n",
    "\n",
    "y_train_comp = np.concatenate((y_train, y_val))\n",
    "\n",
    "kne = KNeighborsClassifier(n_neighbors=6 )\n",
    "\n",
    "kne.fit(x_train, y_train)\n",
    "y_pred = kne.predict(x_test)\n",
    "acc = accuracy_score(y_pred, y_test)\n",
    "print(\"la precision para 6 vecinos es :\", acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obtener tasa de acierto con el conjunto de test para el mejor K"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Ejercicio 4**\n",
    "\n",
    "Cambia la distancia que se emplea (por defecto la L2) por la L1. Ver la documentación para ver cómo poder definir funciones de distancia y pasarlas como parámetro. Esto ralentiza bastante la clasificación pero se puede emplear el parámetro \"n_jobs\" para paralelizar el proceso. Aún así el resultado es muy lento. Podríamos concluir que sk-learn no es una librería adecuada para clasificar con KNN con métricas definidas por el usuario. Por ejemplo no permite definir un algoritmo rápido de tipo kd_tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modifica la función de distancia \n",
    "## x_test[0:100,:]\n",
    "\n",
    "def distancia(x,y):\n",
    "    return np.sum(np.abs(x-y))\n",
    "\n",
    "kne = KNeighborsClassifier(n_neighbors=6, metric=distancia, n_jobs=4)\n",
    "\n",
    "kne.fit(x_train_comp, y_train_comp)\n",
    "y_pred = kne.predict(x_test)\n",
    "acc = accuracy_score(y_pred, y_test)\n",
    "print(\"la precision para 6 vecinos es :\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distancia(x,y):\n",
    "    return np.sum(np.abs(x-y))\n",
    "\n",
    "kv = KNeighborsClassifier(n_neighbors=3,metric=distancia,n_jobs=4)\n",
    "kv.fit(x_train_comp,y_train_comp)\n",
    "\n",
    "print(\"predict\")\n",
    "ypred = kv.predict(x_test[0:100,:])\n",
    "acc = accuracy_score(y_test[0:100], ypred[0:100])\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [2,4,8,16,32,64]:\n",
    "    for md in [3, 4, 6, 8, 10, 12]:\n",
    "        \n",
    "        clf = make_pipeline(PCA(n_components=n), KNeighborsClassifier(n_neighbors=md))\n",
    "        \n",
    "        clf.fit(x_train,y_train)\n",
    "        ypred = clf.predict(x_val)\n",
    "        acc = accuracy_score(y_val, ypred)\n",
    "        print(acc)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr = np.concatenate((x_train, x_val))\n",
    "targets_tr = ((y_train, y_val))\n",
    "clf = make_pipeline(PCA(n_components=n), KNeighborsClassifier(n_neighbors=md))\n",
    "\n",
    "clf.fit(data_tr,targets_tr)\n",
    "ypred = clf.predict(x_test)\n",
    "acc = accuracy_score(y_test, ypred)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
